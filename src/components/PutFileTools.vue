<script setup>
import SparkMD5, { hash } from 'spark-md5'
import { ref } from 'vue'
import axios from 'axios'

const props = defineProps({
  // åˆ‡ç‰‡å¤§å°
  chunkSize: {
    type: Number,
    default: 10 * 1024 * 1024, // 10MB
  },
  /**
   * @description æ ¡éªŒæ–‡ä»¶æ˜¯å¦åœ¨æœåŠ¡å™¨ä¸­å­˜åœ¨
   * @return {Boolean | Array} å¦‚æœåœ¨æœåŠ¡å™¨ä¸­ä¸Šä¼ äº†éƒ¨åˆ†åˆ‡ç‰‡åˆ™è¿”å›è¿™äº›åˆ‡ç‰‡çš„hash
   */
  inspectRequest: {
    type: Function,
    default: '',
  },
  // æ ¡éªŒæ˜¯å¦å·²ç»ä¸Šä¼ åˆ°æœåŠ¡çš„æ¥å£åœ°å€
  inspectApiUrl: {
    type: String,
    default: '',
  },
  // ä¸Šä¼ æ–‡ä»¶çš„æ¥å£åœ°å€
  uploadApiUrl: {
    type: String,
    default: '',
  },
  // åˆ‡ç‰‡ä¸Šä¼ çš„å¹¶å‘æ•°
  concurrencyNumber: {
    type: Number,
    default: 3,
  },
})

const emits = defineEmits([
  'onUploadProgress',
  'uploadError',
  'onChange',
  'onUploadFinish',
])

let blobSlice = null
let file = null
// æ•´ä¸ªæ–‡ä»¶çš„hash
let computedHash = ''
// æ–‡ä»¶å¤§å°
let fileSize = 0
// åˆ‡ç‰‡æ•°
let chunkNumber = 0
// å½“å‰å¤„ç†çš„åˆ‡ç‰‡ç´¢å¼•
let currentChunkIndex = 0
// å½“å‰ä¸Šä¼ çš„åˆ‡ç‰‡ç´¢å¼•
let currentUploadChunkIndex = 0
// æ˜¯å¦å·²ç»åœ¨æœåŠ¡å™¨å­˜åœ¨
let isLoaded = false
let fileReader = null
// ä¸Šä¼ è¿›åº¦
let progress = 0
let waitUploadChunkQueue = ref([])
let spark = null
// å·²ä¸Šä¼ å¤§å°
let uploadedSize = 0

function init() {
  computedHash = ''
  fileSize = 0
  uploadedSize = 0
  progress = 0
  isLoaded = false
  chunkNumber = 0
  currentChunkIndex = 0
  currentUploadChunkIndex = 0
  file = null
  waitUploadChunkQueue.value = []
}

async function onchange(e) {
  init()
  blobSlice =
    File.prototype.slice ||
    File.prototype.mozSlice ||
    File.prototype.webkitSlice
  file = e.target.files[0]
  emits('onChange', file)
  fileProcessing()
}

// æŠŠæ–‡ä»¶å¤„ç†æˆåˆ‡ç‰‡
function fileProcessing() {
  fileSize = file.size
  console.log(
    'ğŸš€ ~ file: PutFileTools.vue:79 ~ fileProcessing ~ fileSize:',
    fileSize
  )
  chunkNumber = Math.ceil(file.size / props.chunkSize)
  spark = new SparkMD5.ArrayBuffer()
  fileReader = new FileReader()
  currentChunkIndex = 0

  fileReader.onload = async function (e) {
    const chunkFormData = new FormData()
    // åˆ‡ç‰‡çš„hash
    let chunkHash = SparkMD5.ArrayBuffer.hash(e.target.result)

    spark.append(e.target.result)
    // åˆ‡ç‰‡æ–‡ä»¶
    chunkFormData.append('chunk', new Blob([e.target.result]))
    // åˆ‡ç‰‡æ–‡ä»¶hash
    chunkFormData.append('chunkHash', chunkHash)

    waitUploadChunkQueue.value.push(fileUploadRequest(chunkFormData))
    currentChunkIndex++
    if (currentChunkIndex < chunkNumber) {
      loadNext()
    } else {
      computedHash = spark.end()
      isLoaded = await inspectRequest(computedHash)
      cheakChunkUpload()
    }
  }

  fileReader.onerror = function () {
    console.warn('oops, something went wrong.')
  }
  loadNext()
}

// è¯»å–æ–‡ä»¶åˆ‡ç‰‡
function loadNext() {
  const start = currentChunkIndex * props.chunkSize
  const end =
    start + props.chunkSize >= file.size ? file.size : start + props.chunkSize
  // æŒ‰å­—èŠ‚è¯»å–æ–‡ä»¶å†…å®¹
  fileReader.readAsArrayBuffer(blobSlice.call(file, start, end))
}

// æ ¡éªŒæ–‡ä»¶æ˜¯å¦åœ¨æœåŠ¡å™¨ä¸­å­˜åœ¨
async function inspectRequest(computedHash) {
  if (props.inspectRequest) {
    const data = await props.inspectRequest(computedHash)
    return data
  } else {
    return false
  }
}

// ä¸Šä¼ è¯·æ±‚
function fileUploadRequest(chunkFormData) {
  console.log(
    'ğŸš€ ~ file: PutFileTools.vue:151 ~ fileUploadRequest ~ chunkFormData:',
    chunkFormData.values()
  )
  return new Promise((resolve) => {
    chunkFormData.append('hash',computedHash)
    axios({
      method: 'POST',
      url: props.uploadApiUrl,
      data: chunkFormData,
      headers: { hash:computedHash, chunkHash: chunkFormData.get('chunkHash') },
      onUploadProgress: function (progressEvent) {
        progress = progressEvent.loaded / fileSize
        emits('onUploadProgress', progress)
      },
    }).then((res) => {
      console.log("ğŸš€ ~ file: PutFileTools.vue:167 ~ returnnewPromise ~ res:", res)
      
    }).catch((error) => {
      emits('uploadError', error)
    })
  })
}

// åˆ‡ç‰‡ä¸Šä¼ 
async function chunkUpload() {
  console.log(
    'ğŸš€ ~ file: PutFileTools.vue:165 ~ chunkUpload ~ waitUploadChunkQueue:',
    waitUploadChunkQueue
  )

  const uploadChunkQueue = waitUploadChunkQueue.value.splice(0, 3)
  Promise.all([
    uploadChunkQueue[0](computedHash),
    uploadChunkQueue[1](computedHash),
    uploadChunkQueue[2](computedHash),
  ])
}

async function cheakChunkUpload() {
  if (isLoaded === true) {
    // éªŒè¯æ–‡ä»¶æ˜¯å¦å·²ç»åœ¨æœåŠ¡ç«¯å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨ï¼Œé‚£å°±ä¸ç”¨ä¸Šä¼ äº†ï¼Œç›¸å½“äºç§’ä¼ æˆåŠŸã€‚
    progress = 100
    emits('onUploadProgress', progress)
  } else {
    if (isLoaded === false) {
      chunkUpload()
    } else if (Object.prototype.toString.call(isLoaded) === '[object Array]') {
      // if (
      //   isLoaded.includes(
      //     waitUploadChunkQueue.value[currentUploadChunkIndex]?.chunkHash
      //   )
      // ) {
      //   uploadedSize += props.chunkSize
      //   currentUploadChunkIndex++
      //   chunkUpload()
      // } else {
      //   cheakChunkUpload()
      // }
    }
  }

  // if (currentUploadChunkIndex < chunkNumber) {
  //   const res = await fileUploadRequest(waitUploadChunkQueue.value[currentUploadChunkIndex])
  //   console.log("ğŸš€ ~ file: PutFileTools.vue:192 ~ cheakChunkUpload ~ res:", res)
  //   currentUploadChunkIndex++
  //   chunkUpload()
  //   if (currentUploadChunkIndex < props.concurrencyNumber) chunkUpload()
  // }
}
</script>

<template>
  <div class="greetings">
    <input type="file" @change="onchange" />
  </div>
</template>
